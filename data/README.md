# ğŸ“ Dossier data/ - Eye of Emergency

Ce dossier contient toutes les donnÃ©es du projet Eye of Emergency, organisÃ©es selon le workflow du pipeline intÃ©grÃ©.

---

## ğŸ“‚ **Structure des sous-dossiers**

### `raw/` - DonnÃ©es brutes et intermÃ©diaires
Fichiers produits par les Ã©tapes 1-2 du pipeline (nettoyage et partitionnement)

| **Fichier** | **Description** | **Taille** | **Ã‰tape pipeline** |
|-------------|-----------------|------------|-------------------|
| `original_train_tweets.csv` | **Dataset source** - DonnÃ©es brutes originales | 7,613 tweets | Input initial |
| `original_train_tweets_with_duplicates.csv` | **Backup automatique** avant nettoyage | 7,613 tweets | Sauvegarde Ã©tape 1 |
| `original_train_tweets_cleaned.csv` | **NettoyÃ© des doublons** (111 suppressions) | 7,502 tweets | Sortie Ã©tape 1 |
| `train_tweets.csv` | **Partition train** aprÃ¨s split stratifiÃ© 90/10 | 6,753 tweets | Sortie Ã©tape 2 |
| `test_tweets.csv` | **Partition test** aprÃ¨s split stratifiÃ© 90/10 | 749 tweets | Sortie Ã©tape 2 |

### `processed/` - DonnÃ©es finales optimisÃ©es  
Fichiers produits par les Ã©tapes 3-5 du pipeline (preprocessing et validation)

| **Fichier** | **Description** | **Taille** | **Ã‰tape pipeline** |
|-------------|-----------------|------------|-------------------|
| `train_optimized.csv` | **ğŸ¯ DATASET FINAL TRAIN** - 16 features optimisÃ©es | 6,185 tweets Ã— 20 colonnes | Sortie Ã©tape 3+5 |
| `test_cleaned.csv` | **ğŸ¯ DATASET FINAL TEST** - Texte nettoyÃ© uniquement | 749 tweets Ã— 6 colonnes | Sortie Ã©tape 4 |
| `train_optimized_with_leaks.csv` | **Backup automatique** avant nettoyage final des fuites | 6,185 tweets Ã— 20 colonnes | Sauvegarde Ã©tape 5 |

---

## ğŸ”„ **Workflow de gÃ©nÃ©ration**

### **Ã‰tapes automatiques (via `run_pipeline.py`)**

```mermaid
original_train_tweets.csv (7,613)
    â†“ Ã‰tape 1: Nettoyage doublons
original_train_tweets_cleaned.csv (7,502)
    â†“ Ã‰tape 2: Split stratifiÃ© 90/10
train_tweets.csv (6,753) + test_tweets.csv (749)
    â†“ Ã‰tape 3: Feature engineering train
train_optimized.csv (6,185 Ã— 20)
    â†“ Ã‰tape 4: Nettoyage test
test_cleaned.csv (749 Ã— 6)
    â†“ Ã‰tape 5: Nettoyage fuites finales
train_optimized.csv (mis Ã  jour, 0 fuite garantie)
```

### **Commande de gÃ©nÃ©ration**
```bash
# Depuis la racine du projet
python run_pipeline.py
```

---

## ğŸ“Š **Datasets finaux pour ML**

### **ğŸš‚ Train : `processed/train_optimized.csv`**
- **Usage** : EntraÃ®nement des modÃ¨les de machine learning
- **Taille** : 6,185 tweets Ã— 20 colonnes
- **Distribution** : 59.2% non-urgence, 40.8% urgence (ratio 1.45 optimal)
- **Features** : 16 optimisÃ©es + 4 mÃ©tadonnÃ©es (id, keyword, target, text_cleaned)
- **QualitÃ©** : Score d'intÃ©gritÃ© 100/100, zÃ©ro fuite garantie

**Features ML (16) :**
```
â€¢ Urgence/Contenu:     has_emergency_word, emergency_word_count, emergency_density, urgency_score
â€¢ Structure/Liens:     has_url, url_count, has_mention, mention_count  
â€¢ MÃ©triques textuelles: text_length, word_count, char_count, avg_word_length
â€¢ Signaux Ã©motionnels: exclamation_count, intense_punctuation
â€¢ Analyse linguistique: stopword_ratio
â€¢ CohÃ©rence metadata:  keyword_in_text
```

### **ğŸ§ª Test : `processed/test_cleaned.csv`**
- **Usage** : Ã‰valuation finale des modÃ¨les entraÃ®nÃ©s
- **Taille** : 749 tweets Ã— 6 colonnes  
- **Distribution** : 57.4% non-urgence, 42.6% urgence
- **Contenu** : Texte nettoyÃ© uniquement (pas de features pour Ã©viter les fuites)
- **Colonnes** : id, keyword, location, text, target, text_cleaned

---

## âœ… **Validation et intÃ©gritÃ©**

### **Tests automatiques rÃ©ussis**
- âœ… **Aucune fuite de donnÃ©es** entre train et test (validation automatique)
- âœ… **Distribution prÃ©servÃ©e** aprÃ¨s chaque transformation  
- âœ… **ReproductibilitÃ© garantie** (random_state=42 fixe)
- âœ… **Backups automatiques** avant chaque modification critique

### **MÃ©triques de qualitÃ©**
- **RÃ©duction contrÃ´lÃ©e** : 7,613 â†’ 6,185 tweets (-18.7% stratÃ©gique)
- **Features optimisÃ©es** : 16 sÃ©lectionnÃ©es pour maximiser le pouvoir prÃ©dictif
- **IntÃ©gritÃ© parfaite** : Score 100/100 avec validation automatique
- **Pipeline reproductible** : MÃªme rÃ©sultat Ã  chaque exÃ©cution

---

## ğŸš€ **Utilisation pour ML**

### **Chargement des donnÃ©es finales**
```python
import pandas as pd

# Dataset d'entraÃ®nement (avec features)
train_df = pd.read_csv('data/processed/train_optimized.csv')
print(f"Train: {len(train_df)} tweets, {len(train_df.columns)} colonnes")

# Dataset de test (pour Ã©valuation finale)
test_df = pd.read_csv('data/processed/test_cleaned.csv') 
print(f"Test: {len(test_df)} tweets, {len(test_df.columns)} colonnes")

# Features pour ML (excluant mÃ©tadonnÃ©es)
feature_cols = [col for col in train_df.columns 
                if col not in ['id', 'keyword', 'target', 'text_cleaned']]
X_train = train_df[feature_cols]
y_train = train_df['target']
```

### **Prochaines Ã©tapes recommandÃ©es**
1. **EntraÃ®nement ML immÃ©diat** : Utiliser `train_optimized.csv` avec les 16 features
2. **Validation croisÃ©e** : Appliquer sur les 16 features optimisÃ©es du train uniquement
3. **Ã‰valuation finale** : 
   - Charger `test_cleaned.csv` (texte nettoyÃ© seulement)
   - Appliquer le **mÃªme feature engineering** qu'au train au moment de la prÃ©diction
   - âš ï¸ **IMPORTANT** : Ne jamais prÃ©-calculer les features sur le test (risque de fuite)
4. **Production** : Pipeline complet = nettoyage + feature engineering + prÃ©diction en temps rÃ©el

### **âš ï¸ Point critique : Feature engineering sur le test**
```python
# âŒ INCORRECT : Features prÃ©-calculÃ©es sur le test (risque de fuite)
# test_with_features = apply_feature_engineering(test_df)  # JAMAIS !

# âœ… CORRECT : Feature engineering au moment de la prÃ©diction
import pandas as pd
import joblib
from src.preprocess_train import OptimizedEmergencyPreprocessor

# 1. Charger le modÃ¨le entraÃ®nÃ© et le preprocessor
model = joblib.load('trained_model.pkl')
preprocessor = OptimizedEmergencyPreprocessor()

# 2. Charger le test (texte nettoyÃ© uniquement)
test_df = pd.read_csv('data/processed/test_cleaned.csv')

# 3. Feature engineering + prÃ©diction en temps rÃ©el (approche optimisÃ©e)
predictions = []
feature_names = ['text_length', 'word_count', 'char_count', 'has_emergency_word', 
                'emergency_word_count', 'emergency_density', 'has_url', 'url_count',
                'has_mention', 'mention_count', 'exclamation_count', 'intense_punctuation',
                'avg_word_length', 'urgency_score', 'stopword_ratio', 'keyword_in_text']

for _, row in test_df.iterrows():
    # Feature engineering en temps rÃ©el (pas de stockage permanent)
    features_dict = preprocessor.extract_optimized_features(row)
    # Convertir en format attendu par le modÃ¨le
    X_test = pd.DataFrame([[features_dict[col] for col in feature_names]], 
                         columns=feature_names)
    pred = model.predict(X_test)[0]
    predictions.append(pred)

# 4. Ã‰valuation finale
y_true = test_df['target']
accuracy = (predictions == y_true).mean()
print(f"Accuracy finale: {accuracy:.3f}")
```

### **ğŸ¯ RÃ©sumÃ© de l'approche correcte**
- âœ… **Train** : Features prÃ©-calculÃ©es et stockÃ©es (`train_optimized.csv`)
- âœ… **Test** : Texte nettoyÃ© uniquement (`test_cleaned.csv`) - **JAMAIS de features prÃ©-calculÃ©es**
- âœ… **Ã‰valuation** : Feature engineering appliquÃ© **dynamiquement** lors des prÃ©dictions
- âœ… **Production** : MÃªme approche = nettoyage + feature engineering + prÃ©diction en temps rÃ©el

---

**ğŸ“‹ RÃ‰SUMÃ‰ : Datasets Eye of Emergency V3.1 prÃªts pour production ML avec intÃ©gritÃ© parfaite et features optimisÃ©es**


