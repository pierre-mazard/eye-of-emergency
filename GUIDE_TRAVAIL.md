# üìã Guide de Travail - Eye of Emergency

## üéØ Objectif
Ce guide pr√©sente toutes les √©tapes √† suivre pour mener √† bien le projet Eye of Emergency, de la veille th√©orique √† la livraison finale du mod√®le.

---

## üìö Phase 1 : Veille NLP 

### ‚úÖ T√¢ches √† effectuer :

1. **Compl√©ter la section "Veille NLP" du README.md**
   - [ ] Text Mining vs Natural Language Processing
   - [ ] Sous-domaines du NLP (sentiment analysis, NER, POS tagging)
   - [ ] Applications concr√®tes du NLP
   - [ ] Stop-words (d√©finition, importance, exemples)
   - [ ] Traitement des caract√®res sp√©ciaux et ponctuation
   - [ ] Tokenisation et N-grams
   - [ ] Stemming vs Lemmatisation
   - [ ] M√©thodes de vectorisation (Bag of Words, TF-IDF)
   - [ ] Bagging vs Boosting

2. **Cr√©er une pr√©sentation de veille**
   - [ ] Synth√®se des concepts √©tudi√©s
   - [ ] Exemples concrets d'applications
   - [ ] Justification des choix techniques pour le projet

### üìã Livrables :
- README.md compl√©t√© (section veille)
- Pr√©sentation de veille (PowerPoint/PDF)

---

## üîß Phase 2 : Setup et Pr√©paration 

### ‚úÖ T√¢ches √† effectuer :

1. **Installation de l'environnement**
   ```bash
   # Cloner le repository
   git clone https://github.com/pierre-mazard/eye-of-emergency.git
   cd eye-of-emergency
   
   # Installer les d√©pendances
   pip install -r requirements.txt
   ```

2. **T√©l√©chargement des donn√©es**
   - [ ] T√©l√©charger le dataset "Disaster Tweets" depuis Kaggle
   - [ ] Placer le fichier dans `data/raw/disaster_tweets.csv`
   - [ ] V√©rifier l'int√©grit√© des donn√©es

3. **Configuration des outils NLP**
   - [ ] T√©l√©charger les corpus NLTK n√©cessaires
   - [ ] Installer le mod√®le spaCy fran√ßais/anglais
   ```python
   import nltk
   nltk.download('stopwords')
   nltk.download('punkt')
   nltk.download('wordnet')
   
   # Pour spaCy
   python -m spacy download en_core_web_sm
   ```

### üìã Livrables :
- Environnement fonctionnel
- Dataset disponible dans `data/raw/`

---

## üîç Phase 3 : Exploration des Donn√©es 

### ‚úÖ T√¢ches dans `notebooks/eye_of_emergency_analysis.ipynb` :

1. **Chargement et aper√ßu des donn√©es**
   - [ ] Importer les librairies n√©cessaires
   - [ ] Charger le dataset depuis `data/raw/disaster_tweets.csv`
   - [ ] Afficher les premi√®res lignes et infos g√©n√©rales
   - [ ] Analyser la structure des donn√©es

2. **Analyse des donn√©es manquantes**
   - [ ] Identifier les valeurs manquantes par colonne
   - [ ] Visualiser les patterns de donn√©es manquantes
   - [ ] D√©cider des strat√©gies de traitement

3. **Analyse des doublons**
   - [ ] D√©tecter les tweets en doublon
   - [ ] Analyser l'impact des doublons
   - [ ] D√©cider de la strat√©gie de d√©duplication

4. **Analyse exploratoire sp√©cifique au NLP**
   - [ ] Distribution des classes (catastrophe vs non-catastrophe)
   - [ ] Distribution des longueurs de tweets
   - [ ] Analyse des mots-cl√©s les plus fr√©quents
   - [ ] Analyse des localisations
   - [ ] Nuages de mots pour chaque classe
   - [ ] Analyse des caract√®res sp√©ciaux et emojis

5. **Visualisations**
   - [ ] Graphiques de distribution
   - [ ] WordClouds par classe
   - [ ] Heatmaps de corr√©lation
   - [ ] Sauvegarder les graphiques dans `results/figures/`

### üìã Livrables :
- Notebook avec EDA compl√®te
- Graphiques sauvegard√©s dans `results/figures/`
- Rapport d'analyse des donn√©es

---

## üßπ Phase 4 : Preprocessing 

### ‚úÖ T√¢ches dans `src/preprocessing.py` :

1. **Cr√©er les fonctions de nettoyage**
   - [ ] Fonction de suppression des URLs
   - [ ] Fonction de suppression des mentions (@username)
   - [ ] Fonction de suppression des hashtags ou conservation
   - [ ] Fonction de suppression des caract√®res sp√©ciaux
   - [ ] Fonction de conversion en minuscules
   - [ ] Fonction de suppression des emojis (optionnel)

2. **Cr√©er les fonctions de tokenisation**
   - [ ] Fonction de tokenisation simple
   - [ ] Fonction de suppression des stop-words
   - [ ] Fonction de stemming (Porter Stemmer)
   - [ ] Fonction de lemmatisation (spaCy ou NLTK)

3. **Cr√©er le pipeline de preprocessing**
   - [ ] Classe `TextPreprocessor` avec m√©thodes modulaires
   - [ ] M√©thode `fit()` pour ajuster le preprocessing
   - [ ] M√©thode `transform()` pour appliquer le preprocessing
   - [ ] Tests unitaires des fonctions

4. **Appliquer le preprocessing dans le notebook**
   - [ ] Importer les fonctions depuis `src/preprocessing.py`
   - [ ] Tester diff√©rentes strat√©gies de preprocessing
   - [ ] Comparer l'impact sur les donn√©es
   - [ ] G√©n√©rer `data/train.csv` et `data/test.csv`

### üìã Livrables :
- Module `src/preprocessing.py` complet
- Datasets pr√©process√©s dans `data/`
- Documentation des choix de preprocessing

---

## ü§ñ Phase 5 : Mod√©lisation 

### ‚úÖ T√¢ches dans `src/models.py` :

1. **Impl√©mentation de la classe Decision Tree personnalis√©e**
   - [ ] Classe `CustomDecisionTree` from scratch
   - [ ] M√©thodes `fit()`, `predict()`, `score()`
   - [ ] Crit√®res de division (Gini, Entropy)
   - [ ] Gestion de l'overfitting (max_depth, min_samples_split)

2. **Pr√©paration des autres mod√®les**
   - [ ] Configuration Logistic Regression
   - [ ] Configuration Random Forest
   - [ ] Configuration XGBoost
   - [ ] Configuration SVM

3. **D√©veloppement dans le notebook**
   - [ ] Import et vectorisation des textes (TF-IDF, Bag of Words)
   - [ ] Split train/validation/test
   - [ ] Entra√Ænement des 5 mod√®les
   - [ ] GridSearch pour l'optimisation des hyperparam√®tres
   - [ ] Cross-validation

4. **√âvaluation des mod√®les**
   - [ ] Calcul des m√©triques (Accuracy, Precision, Recall, F1-score)
   - [ ] Matrices de confusion
   - [ ] Courbes ROC et calcul AUC
   - [ ] Comparaison des temps d'entra√Ænement
   - [ ] Analyse des erreurs

### üìã Livrables :
- Module `src/models.py` avec classe Decision Tree
- 5 mod√®les entra√Æn√©s et optimis√©s
- M√©triques de performance d√©taill√©es

---

## üíæ Phase 6 : Sauvegarde et Documentation 

### ‚úÖ T√¢ches √† effectuer :

1. **Sauvegarde des mod√®les**
   - [ ] Sauvegarder tous les mod√®les dans `results/models/`
   - [ ] Sauvegarder les vectoriseurs (TF-IDF, BoW)
   - [ ] Sauvegarder le pipeline de preprocessing
   - [ ] Cr√©er un fichier de m√©tadonn√©es des mod√®les

2. **Sauvegarde des r√©sultats**
   - [ ] Export des m√©triques en JSON/CSV
   - [ ] Sauvegarde des graphiques de performance
   - [ ] Cr√©ation d'un rapport de comparaison des mod√®les

3. **Documentation finale**
   - [ ] Compl√©ter le README.md avec les r√©sultats
   - [ ] Documenter les choix techniques
   - [ ] Ajouter des instructions d'utilisation
   - [ ] Cr√©er des exemples d'usage

### üìã Livrables :
- Mod√®les sauvegard√©s dans `results/models/`
- Documentation compl√®te
- README.md finalis√©

---

## üìä Phase 7 : Analyse et Conclusion 

### ‚úÖ T√¢ches finales :

1. **Analyse comparative des mod√®les**
   - [ ] Tableau de comparaison des performances
   - [ ] Analyse des forces/faiblesses de chaque mod√®le
   - [ ] Justification du choix du mod√®le final
   - [ ] Analyse du rapport performance/complexit√©

2. **Validation finale**
   - [ ] Test sur le dataset de test final
   - [ ] Validation des performances en conditions r√©elles
   - [ ] Tests de robustesse

3. **Pr√©sentation des r√©sultats**
   - [ ] Cr√©ation d'une pr√©sentation finale
   - [ ] D√©monstration du mod√®le en action
   - [ ] Recommandations pour la production

### üìã Livrables :
- Pr√©sentation finale des r√©sultats
- Mod√®le recommand√© pour la production
- Documentation d'utilisation

---


## ‚úÖ Checklist de Validation

### Avant de passer √† la phase suivante :
- [ ] Tous les livrables de la phase sont compl√©t√©s
- [ ] Le code est test√© et fonctionnel
- [ ] La documentation est √† jour
- [ ] Les r√©sultats sont sauvegard√©s
- [ ] Review par un autre membre de l'√©quipe (si applicable)

### Points de contr√¥le qualit√© :
- [ ] Code propre et comment√©
- [ ] Respect des conventions de nommage
- [ ] Gestion des erreurs
- [ ] Reproductibilit√© des r√©sultats
- [ ] Performance acceptable

---

## üÜò Support et Ressources

### Documentation utile :
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [NLTK Documentation](https://www.nltk.org/)
- [spaCy Documentation](https://spacy.io/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)

### En cas de blocage :
1. Consulter la documentation officielle
2. Chercher sur Stack Overflow
3. Demander de l'aide √† l'√©quipe
4. Documenter le probl√®me et la solution trouv√©e

---

## üìù Notes Importantes

- **Versioning** : Commiter r√©guli√®rement avec des messages clairs
- **Backup** : Sauvegarder le travail quotidiennement
- **Communication** : Tenir l'√©quipe inform√©e des avanc√©es
- **Qualit√©** : Privil√©gier la qualit√© √† la rapidit√©
- **Documentation** : Documenter au fur et √† mesure, pas √† la fin !

---
