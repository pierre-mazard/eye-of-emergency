# Eye of Emergency ğŸš¨

DÃ©veloppement d'un modÃ¨le d'apprentissage automatique capable de classer des tweets signalant des catastrophes naturelles rÃ©elles pour aider les intervenants d'urgence et le public Ã  accÃ©der Ã  des informations prÃ©cises et fiables en pÃ©riode de crise.

## ğŸ“‹ Table des matiÃ¨res

- [Contexte du projet](#contexte-du-projet)
- [DonnÃ©es](#donnÃ©es)
- [Veille NLP](#veille-nlp)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Structure du projet](#structure-du-projet)
- [MÃ©thodologie](#mÃ©thodologie)
- [Algorithmes utilisÃ©s](#algorithmes-utilisÃ©s)
- [RÃ©sultats et analyse](#rÃ©sultats-et-analyse)
- [Conclusion](#conclusion)

## ğŸ¯ Contexte du projet

L'objectif de ce projet est de dÃ©velopper un modÃ¨le d'apprentissage automatique capable de distinguer les tweets informatifs concernant des catastrophes naturelles rÃ©elles de ceux qui ne le sont pas. Cette classification automatique permettra d'aider les services d'urgence Ã  identifier rapidement les informations fiables lors de situations de crise.

## ğŸ“Š DonnÃ©es

Le projet utilise le dataset **Disaster Tweets** qui contient les colonnes suivantes :

- **id** : Identifiant unique pour chaque tweet
- **text** : Contenu textuel du tweet
- **location** : Localisation d'oÃ¹ a Ã©tÃ© envoyÃ© le tweet
- **keyword** : Mot-clÃ© associÃ© au tweet
- **target** : Variable cible indiquant si un tweet concerne une catastrophe rÃ©elle (1) ou non (0)

## ğŸ§  Veille NLP

### 1. Text Mining vs Natural Language Processing
- **Text Mining** : [Ã€ complÃ©ter]
- **NLP** : [Ã€ complÃ©ter]
- **Points communs** : [Ã€ complÃ©ter]
- **DiffÃ©rences** : [Ã€ complÃ©ter]

### 2. Sous-domaines du NLP
- **Analyse de sentiments** : [Ã€ complÃ©ter]
- **Named Entity Recognition (NER)** : [Ã€ complÃ©ter]
- **Part-of-Speech (POS) Tagging** : [Ã€ complÃ©ter]

### 3. Applications concrÃ¨tes du NLP
[Ã€ complÃ©ter]

### 4. Stop-words
- **DÃ©finition** : [Ã€ complÃ©ter]
- **Importance de leur suppression** : [Ã€ complÃ©ter]
- **Exemples** : [Ã€ complÃ©ter]

### 5. Traitement des caractÃ¨res spÃ©ciaux et ponctuation
[Ã€ complÃ©ter]

### 6. Tokenisation et N-grams
- **Token** : [Ã€ complÃ©ter]
- **N-gram** : [Ã€ complÃ©ter]
- **Processus de tokenisation** : [Ã€ complÃ©ter]

### 7. Stemming vs Lemmatisation
- **Stemming** : [Ã€ complÃ©ter]
- **Lemmatisation** : [Ã€ complÃ©ter]
- **DiffÃ©rences** : [Ã€ complÃ©ter]
- **Cas d'usage** : [Ã€ complÃ©ter]

### 8. MÃ©thodes de vectorisation
- **Bag of Words** : [Ã€ complÃ©ter]
- **TF-IDF** : [Ã€ complÃ©ter]

## ğŸ”§ PrÃ©requis

- Python 3.7+
- Jupyter Notebook
- BibliothÃ¨ques Python : pandas, numpy, scikit-learn, nltk, matplotlib, seaborn ... 

## ğŸš€ Installation

```bash
# Cloner le repository
git clone https://github.com/pierre-mazard/eye-of-emergency.git
cd eye-of-emergency

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer Jupyter Notebook
jupyter notebook
```

## ğŸ“ Structure du projet

```
eye-of-emergency/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/                        # Images pour la documentation (README, etc.)
â”‚   â””â”€â”€ README.md                      # Documentation des ressources visuelles
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ disaster_tweets.csv        # Dataset brut original
â”‚   â”œâ”€â”€ train.csv                      # Dataset d'entraÃ®nement prÃ©processÃ©
â”‚   â”œâ”€â”€ test.csv                       # Dataset de test prÃ©processÃ©
â”‚   â””â”€â”€ README.md                      # Documentation du dossier data
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eye_of_emergency_analysis.ipynb 
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ models.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â””â”€â”€ README.md                  # Documentation des visualisations
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ README.md                  # Documentation des modÃ¨les sauvegardÃ©s
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ” MÃ©thodologie

### 1. Veille NLP
Ã‰tude des concepts fondamentaux du traitement du langage naturel

### 2. Exploration des donnÃ©es
- Analyse des donnÃ©es manquantes et doublons
- Visualisations spÃ©cifiques au NLP (nuages de mots, distribution des longueurs, etc.)

### 3. PrÃ©processing
- Nettoyage des donnÃ©es textuelles
- Pipeline de preprocessing personnalisÃ©

### 4. ModÃ©lisation
- DÃ©veloppement et comparaison de 5 modÃ¨les
- Optimisation par GridSearch

### 5. Ã‰valuation
- MÃ©triques d'Ã©valuation avec optimisation du F1-score

## ğŸ¤– Algorithmes utilisÃ©s

### ModÃ¨les de classification Ã©tudiÃ©s

1. **RÃ©gression Logistique**
   - [Ã€ complÃ©ter]

2. **Decision Tree**
   - ImplÃ©mentation d'une classe Python personnalisÃ©e
   - [Ã€ complÃ©ter]

3. **Random Forest**
   - [Ã€ complÃ©ter]

4. **XGBoost**
   - [Ã€ complÃ©ter]

5. **Support Vector Machine (SVM)**
   - [Ã€ complÃ©ter]

### Bagging vs Boosting
- **Bagging** : [Ã€ complÃ©ter]
- **Boosting** : [Ã€ complÃ©ter]

## ğŸ“ˆ RÃ©sultats et analyse

### Analyse exploratoire des donnÃ©es
- **DonnÃ©es manquantes** : [Ã€ complÃ©ter]
- **Doublons** : [Ã€ complÃ©ter]
- **Visualisations NLP** : [Ã€ complÃ©ter - nuages de mots, distribution des longueurs, etc.]

### Performance des modÃ¨les
- **Meilleur modÃ¨le** : [Ã€ complÃ©ter]
- **MÃ©triques d'Ã©valuation** :
  - **Accuracy** : [Ã€ complÃ©ter]
  - **Precision** : [Ã€ complÃ©ter]
  - **Recall** : [Ã€ complÃ©ter]
  - **F1-score** : [Ã€ complÃ©ter]
- **Matrice de confusion** : [Ã€ complÃ©ter]
- **Rapport de classification** : [Ã€ complÃ©ter]

## ğŸ¯ Conclusion

### Comparaison des modÃ¨les
[Ã€ complÃ©ter - analyse comparative des 5 modÃ¨les]

### ModÃ¨le sÃ©lectionnÃ©
[Ã€ complÃ©ter - justification du choix final]

### EfficacitÃ© et performance
[Ã€ complÃ©ter - Ã©valuation de l'efficacitÃ© du modÃ¨le choisi] 

