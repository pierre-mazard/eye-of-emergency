{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b534f",
   "metadata": {},
   "source": [
    "### Initialisation et test des différents models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81176891",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pass\n",
    "y_train = pass\n",
    "\n",
    "model_sgd = SGDClassifier(max_iter=1000) \n",
    "model_tree = DecisionTreeClassifier(max_depth=10)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "for model in (model_sgd, model_tree, model_knn):\n",
    "      model.fit(X_train, y_train)\n",
    "      print(f\"{model.__class__.__name__} score: {model.score(X_test, y_test)}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90f794",
   "metadata": {},
   "source": [
    "### `VotingClassifier`\n",
    "\n",
    "- ``voting soft`` = prend la probabilité de chaque classe et fait la moyenne\n",
    "- ``voting hard`` = sélectionne la classe avec le plus de votes\n",
    "\n",
    "Vote soft un peu meilleur quand les models sont bien qualibrés, à utiliser quand on a des models qui sortent des probabilités\n",
    "\n",
    "`VotingClassifier` n'est pas une technique d'ensemble très efficace, elle ne garantie pas le respect du critère de diversité de la foule<br>\n",
    "\n",
    "**loi des grands nombe** :\n",
    "- taille\n",
    "- compétence\n",
    "- diversite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01700a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_voting = VotingClassifier([('SGD', model_sgd),\n",
    "                                 ['Tree', model_tree],\n",
    "                                 ['Knn', model_knn]],\n",
    "                                    voting='soft')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555516c6",
   "metadata": {},
   "source": [
    "Pour respecter le critère de diversité, il fzut utiliser les techniques de **bagging** ou **boosting**\n",
    "\n",
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a23a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(base_estimator = KNeighborsClassifier(), \n",
    "                          n_estimators= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators= 100, max_depth = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02df68",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec12b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators= 100)\n",
    "\n",
    "# Faire une GridSearchCV et tester des base_estimators différents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5628a",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "entraine un estimateru par dessus les pred des différents models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "meta_model = StackingClassifier([('SGD', model_sgd),\n",
    "('Tree', model_tree),\n",
    "('Knn', model_knn)],\n",
    "final_estimator = KNeighborsClassifier())\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
